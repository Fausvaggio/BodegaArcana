{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn==1.7.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ns4PMgJ2oqyU",
        "outputId": "fcc2c246-bf98-4e63-d47d-4f3bc8548998"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-learn==1.7.2\n",
            "  Downloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.7.2) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.7.2) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.7.2) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.7.2) (3.6.0)\n",
            "Downloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "Successfully installed scikit-learn-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PASO 1: INSTALAR E IMPORTAR LIBRERÍAS"
      ],
      "metadata": {
        "id": "53ck-coRvWlx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Primero, nos aseguramos de tener todo lo que necesitamos.\n",
        "# pandas es para manejar los datos (como si fuera una hoja de cálculo de Excel).\n",
        "# scikit-learn es la biblioteca principal para hacer Machine Learning en Python.\n",
        "# joblib nos servirá para guardar nuestro modelo una vez que esté entrenado.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import joblib\n",
        "\n",
        "print(\"Librerías importadas correctamente.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRQEtBq7vZIM",
        "outputId": "521693b6-81af-4dd1-ab3f-0140f2e7f5d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Librerías importadas correctamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PASO 2: CARGAR Y PREPARAR LOS DATOS"
      ],
      "metadata": {
        "id": "7x89FhvKvbm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ahora, vamos a cargar los archivos CSV que subiste a Colab.\n",
        "# También, añadiremos una columna 'wine_type' para saber si un vino es tinto o blanco\n",
        "# y luego los juntaremos en una sola tabla de datos.\n",
        "\n",
        "try:\n",
        "    red_wine = pd.read_csv('/content/winequality-red.csv', sep=';')\n",
        "    white_wine = pd.read_csv('/content/winequality-white.csv', sep=';')\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: No se encontraron los archivos. Asegúrate de haber subido 'winequality-red.csv' y 'winequality-white.csv' a tu sesión de Colab.\")\n",
        "    exit()\n",
        "\n",
        "# Agregamos la columna para identificar el tipo\n",
        "red_wine['wine_type'] = 'red'\n",
        "white_wine['wine_type'] = 'white'\n",
        "\n",
        "# Combinamos ambos datasets\n",
        "wines = pd.concat([red_wine, white_wine])\n",
        "\n",
        "print(\"Datos cargados y combinados. Total de filas:\", len(wines))\n",
        "print(\"Primeras 5 filas del dataset combinado:\")\n",
        "print(wines.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzlIFoWdvd9d",
        "outputId": "07a55e1a-6f4b-45d1-d009-7b5bcfcaa421"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos cargados y combinados. Total de filas: 6497\n",
            "Primeras 5 filas del dataset combinado:\n",
            "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
            "0            7.4              0.70         0.00             1.9      0.076   \n",
            "1            7.8              0.88         0.00             2.6      0.098   \n",
            "2            7.8              0.76         0.04             2.3      0.092   \n",
            "3           11.2              0.28         0.56             1.9      0.075   \n",
            "4            7.4              0.70         0.00             1.9      0.076   \n",
            "\n",
            "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
            "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
            "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
            "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
            "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
            "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
            "\n",
            "   alcohol  quality wine_type  \n",
            "0      9.4        5       red  \n",
            "1      9.8        5       red  \n",
            "2      9.8        5       red  \n",
            "3      9.8        6       red  \n",
            "4      9.4        5       red  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PASO 3: INGENIERÍA DE CARACTERÍSTICAS Y PREPROCESAMIENTO"
      ],
      "metadata": {
        "id": "ULd_gx3avgeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# El modelo necesita que los datos estén en un formato específico.\n",
        "# 1. Convertiremos la calidad (que es un número del 1 al 10) en categorías ('baja', 'media', 'alta').\n",
        "#    Esto convierte nuestro problema en uno de clasificación, que es más fácil de manejar.\n",
        "# 2. Convertiremos el tipo de vino ('red', 'white') en números (0 y 1), porque los modelos\n",
        "#    de machine learning solo entienden números.\n",
        "\n",
        "# 1. Crear la variable objetivo categórica\n",
        "wines['quality_category'] = wines['quality'].apply(\n",
        "    lambda x: 'baja' if x <= 5 else ('media' if x <= 7 else 'alta')\n",
        ")\n",
        "\n",
        "\n",
        "# 2. Convertir 'wine_type' a formato numérico\n",
        "wines['wine_type'] = wines['wine_type'].apply(lambda x: 0 if x == 'red' else 1)\n",
        "\n",
        "print(\"\\nSe ha creado la columna 'quality_category' y se ha transformado 'wine_type'.\")\n",
        "print(\"Distribución de las nuevas categorías de calidad:\")\n",
        "print(wines['quality_category'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5zwRYXLvi5e",
        "outputId": "651cfd0d-da16-490b-915e-0f116b9cff6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Se ha creado la columna 'quality_category' y se ha transformado 'wine_type'.\n",
            "Distribución de las nuevas categorías de calidad:\n",
            "quality_category\n",
            "media    3915\n",
            "baja     2384\n",
            "alta      198\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PASO 4: DEFINIR CARACTERÍSTICAS (X) Y OBJETIVO (y)"
      ],
      "metadata": {
        "id": "FEKZk8izvlmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vamos a separar nuestra tabla en dos partes:\n",
        "# X: Las características o \"pistas\" que el modelo usará para aprender (todas las columnas menos la calidad).\n",
        "# y: El objetivo que queremos predecir (la 'quality_category').\n",
        "\n",
        "# X son todas las columnas excepto las de calidad\n",
        "X = wines.drop(['quality', 'quality_category'], axis=1)\n",
        "\n",
        "# y es solo la columna que queremos predecir\n",
        "y = wines['quality_category']\n",
        "\n",
        "print(\"\\nCaracterísticas (X) para el modelo:\")\n",
        "print(X.head())\n",
        "print(\"\\nObjetivo (y) a predecir:\")\n",
        "print(y.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBHJf4-Gvoms",
        "outputId": "8354ddd6-0791-4ce6-8a33-f17562220796"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Características (X) para el modelo:\n",
            "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
            "0            7.4              0.70         0.00             1.9      0.076   \n",
            "1            7.8              0.88         0.00             2.6      0.098   \n",
            "2            7.8              0.76         0.04             2.3      0.092   \n",
            "3           11.2              0.28         0.56             1.9      0.075   \n",
            "4            7.4              0.70         0.00             1.9      0.076   \n",
            "\n",
            "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
            "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
            "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
            "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
            "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
            "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
            "\n",
            "   alcohol  wine_type  \n",
            "0      9.4          0  \n",
            "1      9.8          0  \n",
            "2      9.8          0  \n",
            "3      9.8          0  \n",
            "4      9.4          0  \n",
            "\n",
            "Objetivo (y) a predecir:\n",
            "0     baja\n",
            "1     baja\n",
            "2     baja\n",
            "3    media\n",
            "4     baja\n",
            "Name: quality_category, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PASO 5: DIVIDIR LOS DATOS PARA ENTRENAMIENTO Y PRUEBA"
      ],
      "metadata": {
        "id": "GwRFd1-JvqYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Este es un paso CRUCIAL. No podemos usar todos nuestros datos para entrenar el modelo,\n",
        "# porque si no, no tendríamos cómo saber si realmente aprendió algo o si solo se memorizó las respuestas.\n",
        "# Dividimos los datos: 80% para entrenar y 20% para probar.\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"\\nDatos divididos en:\")\n",
        "print(f\"- {len(X_train)} filas para entrenamiento.\")\n",
        "print(f\"- {len(X_test)} filas para prueba.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvoNh_qGvtMA",
        "outputId": "11fca9c5-7e12-47f9-d520-65ec18311c6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Datos divididos en:\n",
            "- 5197 filas para entrenamiento.\n",
            "- 1300 filas para prueba.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PASO 5.1: ESCALAR LAS CARACTERÍSTICAS (PREPARACIÓN PARA LA RED NEURONAL)"
      ],
      "metadata": {
        "id": "ueG_mIsUvu-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Las Redes Neuronales son sensibles a la escala de los datos. Si una característica\n",
        "# tiene un rango mucho más grande que otras (ej. 'total sulfur dioxide' vs 'pH'),\n",
        "# puede dominar el proceso de aprendizaje. Por eso, estandarizamos los datos.\n",
        "# El StandardScaler transforma los datos para que tengan una media de 0 y una desviación estándar de 1.\n",
        "\n",
        "print(\"\\nEscalando los datos para la Red Neuronal...\")\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "print(\"Datos escalados correctamente.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6SACMbqvx54",
        "outputId": "47403de2-d8a4-4151-b034-024afbd4323f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Escalando los datos para la Red Neuronal...\n",
            "Datos escalados correctamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PASO 6: ENTRENAR Y EVALUAR MODELO 1: RANDOM FOREST"
      ],
      "metadata": {
        "id": "0rlyHGONv0nz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ¡La parte divertida! Aquí es donde el algoritmo aprende.\n",
        "# Usaremos un 'RandomForestClassifier', que es como un comité de \"árboles de decisión\" que votan\n",
        "# para decidir la calidad del vino. Es un modelo muy potente y versátil.\n",
        "\n",
        "print(\"\\nIniciando el entrenamiento del modelo RandomForest...\")\n",
        "\n",
        "# Inicializamos el modelo\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Entrenamos el modelo con los datos de entrenamiento (no necesitan estar escalados)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"¡Modelo RandomForest entrenado exitosamente!\")\n",
        "\n",
        "# Evaluamos el rendimiento\n",
        "print(\"\\nEvaluando el modelo RandomForest...\")\n",
        "rf_predictions = rf_model.predict(X_test)\n",
        "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
        "print(f\"\\nPrecisión de RandomForest: {rf_accuracy:.2%}\")\n",
        "print(\"\\nReporte de Clasificación para RandomForest:\")\n",
        "print(classification_report(y_test, rf_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0HMP0Z7v2ri",
        "outputId": "c5e8c58f-d204-4ba9-d6eb-fc4d8abeecf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iniciando el entrenamiento del modelo RandomForest...\n",
            "¡Modelo RandomForest entrenado exitosamente!\n",
            "\n",
            "Evaluando el modelo RandomForest...\n",
            "\n",
            "Precisión de RandomForest: 82.31%\n",
            "\n",
            "Reporte de Clasificación para RandomForest:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        alta       1.00      0.47      0.64        40\n",
            "        baja       0.79      0.77      0.78       477\n",
            "       media       0.84      0.87      0.86       783\n",
            "\n",
            "    accuracy                           0.82      1300\n",
            "   macro avg       0.88      0.71      0.76      1300\n",
            "weighted avg       0.83      0.82      0.82      1300\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PASO 7: ENTRENAR Y EVALUAR MODELO 2: GRADIENT BOOSTING"
      ],
      "metadata": {
        "id": "mgSZl1rFv4tX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient Boosting es otro modelo de ensamble, como Random Forest, pero construye\n",
        "# los árboles de forma secuencial, donde cada nuevo árbol intenta corregir los errores del anterior.\n",
        "\n",
        "print(\"\\nIniciando el entrenamiento del modelo Gradient Boosting...\")\n",
        "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "gb_model.fit(X_train, y_train)\n",
        "print(\"¡Modelo Gradient Boosting entrenado exitosamente!\")\n",
        "\n",
        "print(\"\\nEvaluando el modelo Gradient Boosting...\")\n",
        "gb_predictions = gb_model.predict(X_test)\n",
        "gb_accuracy = accuracy_score(y_test, gb_predictions)\n",
        "print(f\"\\nPrecisión de Gradient Boosting: {gb_accuracy:.2%}\")\n",
        "print(\"\\nReporte de Clasificación para Gradient Boosting:\")\n",
        "print(classification_report(y_test, gb_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xzoFgQ6v6_g",
        "outputId": "f8d8381f-4215-451b-a425-3403830db14e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iniciando el entrenamiento del modelo Gradient Boosting...\n",
            "¡Modelo Gradient Boosting entrenado exitosamente!\n",
            "\n",
            "Evaluando el modelo Gradient Boosting...\n",
            "\n",
            "Precisión de Gradient Boosting: 76.31%\n",
            "\n",
            "Reporte de Clasificación para Gradient Boosting:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        alta       0.75      0.15      0.25        40\n",
            "        baja       0.74      0.67      0.70       477\n",
            "       media       0.78      0.85      0.81       783\n",
            "\n",
            "    accuracy                           0.76      1300\n",
            "   macro avg       0.75      0.56      0.59      1300\n",
            "weighted avg       0.76      0.76      0.75      1300\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PASO 8: ENTRENAR Y EVALUAR MODELO 3: RED NEURONAL (MLP)"
      ],
      "metadata": {
        "id": "yiEOao2wv_FF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Usaremos un Perceptrón Multicapa (MLP), un tipo de red neuronal.\n",
        "# ¡IMPORTANTE! Las redes neuronales DEBEN usar los datos escalados que preparamos en el paso 5.1.\n",
        "\n",
        "print(\"\\nIniciando el entrenamiento del modelo de Red Neuronal (MLP)...\")\n",
        "# Definimos la arquitectura: 2 capas ocultas con 50 neuronas cada una.\n",
        "nn_model = MLPClassifier(hidden_layer_sizes=(50, 50), max_iter=500, random_state=42)\n",
        "nn_model.fit(X_train_scaled, y_train)\n",
        "print(\"¡Modelo de Red Neuronal entrenado exitosamente!\")\n",
        "\n",
        "print(\"\\nEvaluando el modelo de Red Neuronal...\")\n",
        "nn_predictions = nn_model.predict(X_test_scaled)\n",
        "nn_accuracy = accuracy_score(y_test, nn_predictions)\n",
        "print(f\"\\nPrecisión de la Red Neuronal: {nn_accuracy:.2%}\")\n",
        "print(\"\\nReporte de Clasificación para la Red Neuronal:\")\n",
        "print(classification_report(y_test, nn_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3xAG4ejwAPo",
        "outputId": "3b76192e-09b3-46d3-d47c-c0e6c92fa859"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iniciando el entrenamiento del modelo de Red Neuronal (MLP)...\n",
            "¡Modelo de Red Neuronal entrenado exitosamente!\n",
            "\n",
            "Evaluando el modelo de Red Neuronal...\n",
            "\n",
            "Precisión de la Red Neuronal: 75.46%\n",
            "\n",
            "Reporte de Clasificación para la Red Neuronal:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        alta       0.60      0.23      0.33        40\n",
            "        baja       0.70      0.71      0.71       477\n",
            "       media       0.79      0.81      0.80       783\n",
            "\n",
            "    accuracy                           0.75      1300\n",
            "   macro avg       0.70      0.58      0.61      1300\n",
            "weighted avg       0.75      0.75      0.75      1300\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PASO 9: GUARDAR TODOS LOS MODELOS ENTRENADOS"
      ],
      "metadata": {
        "id": "Czl-32pIwCNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ¡Felicidades! Ya tienes tus modelos entrenados.\n",
        "# Ahora guardaremos cada uno de nuestros modelos y el escalador en archivos separados.\n",
        "# Estos archivos son los \"cerebros\" listos para ser usados por nuestra API.\n",
        "\n",
        "# Guardar Modelo 1: Random Forest\n",
        "rf_model_filename = 'wine_quality_rf_model.joblib'\n",
        "joblib.dump(rf_model, rf_model_filename)\n",
        "print(f\"\\nModelo Random Forest guardado en: '{rf_model_filename}'\")\n",
        "\n",
        "# Guardar Modelo 2: Gradient Boosting\n",
        "gb_model_filename = 'wine_quality_gb_model.joblib'\n",
        "joblib.dump(gb_model, gb_model_filename)\n",
        "print(f\"Modelo Gradient Boosting guardado en: '{gb_model_filename}'\")\n",
        "\n",
        "# Guardar Modelo 3: Red Neuronal\n",
        "nn_model_filename = 'wine_quality_nn_model.joblib'\n",
        "joblib.dump(nn_model, nn_model_filename)\n",
        "print(f\"Modelo de Red Neuronal guardado en: '{nn_model_filename}'\")\n",
        "\n",
        "# ¡MUY IMPORTANTE! Guardar también el escalador.\n",
        "# Lo necesitaremos para escalar cualquier dato nuevo antes de pasarlo a la red neuronal.\n",
        "scaler_filename = 'scaler.joblib'\n",
        "joblib.dump(scaler, scaler_filename)\n",
        "print(f\"Escalador guardado en: '{scaler_filename}'\")\n",
        "\n",
        "print(\"\\nProceso completado. Ya puedes descargar los archivos .joblib desde el panel de Colab.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdfunfCZwGVC",
        "outputId": "0fa11453-c257-4db7-d8ff-7a83d719c86a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Modelo Random Forest guardado en: 'wine_quality_rf_model.joblib'\n",
            "Modelo Gradient Boosting guardado en: 'wine_quality_gb_model.joblib'\n",
            "Modelo de Red Neuronal guardado en: 'wine_quality_nn_model.joblib'\n",
            "Escalador guardado en: 'scaler.joblib'\n",
            "\n",
            "Proceso completado. Ya puedes descargar los archivos .joblib desde el panel de Colab.\n"
          ]
        }
      ]
    }
  ]
}